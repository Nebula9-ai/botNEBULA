{
  "nodes": [
    {
      "id": "openAIAssistant_0",
      "position": {
        "x": 2247.7872409176816,
        "y": 288.76831426870274
      },
      "type": "customNode",
      "data": {
        "id": "openAIAssistant_0",
        "label": "OpenAI Assistant",
        "version": 3,
        "name": "openAIAssistant",
        "type": "OpenAIAssistant",
        "baseClasses": [
          "OpenAIAssistant"
        ],
        "category": "Agents",
        "description": "An agent that uses OpenAI Assistant API to pick the tool and args to call",
        "inputParams": [
          {
            "label": "Select Assistant",
            "name": "selectedAssistant",
            "type": "asyncOptions",
            "loadMethod": "listAssistants",
            "id": "openAIAssistant_0-input-selectedAssistant-asyncOptions"
          },
          {
            "label": "Disable File Download",
            "name": "disableFileDownload",
            "type": "boolean",
            "description": "Messages can contain text, images, or files. In some cases, you may want to prevent others from downloading the files. Learn more from OpenAI File Annotation <a target=\"_blank\" href=\"https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages\">docs</a>",
            "optional": true,
            "additionalParams": true,
            "id": "openAIAssistant_0-input-disableFileDownload-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Allowed Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "openAIAssistant_0-input-tools-Tool"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "openAIAssistant_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "selectedAssistant": "3d966968-d306-4247-b4cb-823ba24679a9",
          "tools": [],
          "inputModeration": "",
          "disableFileDownload": ""
        },
        "outputAnchors": [
          {
            "id": "openAIAssistant_0-output-openAIAssistant-OpenAIAssistant",
            "name": "openAIAssistant",
            "label": "OpenAIAssistant",
            "description": "An agent that uses OpenAI Assistant API to pick the tool and args to call",
            "type": "OpenAIAssistant"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 420,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2247.7872409176816,
        "y": 288.76831426870274
      }
    },
    {
      "id": "customTool_0",
      "position": {
        "x": 1078.69977693622,
        "y": -59.31833483547723
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 1,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created in Flowise within chatflow",
        "inputParams": [
          {
            "label": "Select Tool",
            "name": "selectedTool",
            "type": "asyncOptions",
            "loadMethod": "listTools",
            "id": "customTool_0-input-selectedTool-asyncOptions"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "selectedTool": "ac2b70cc-2b17-449f-9ee7-43a07e674f1a"
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "name": "customTool",
            "label": "CustomTool",
            "description": "Use custom tool you've created in Flowise within chatflow",
            "type": "CustomTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 277,
      "selected": false,
      "positionAbsolute": {
        "x": 1078.69977693622,
        "y": -59.31833483547723
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 829.4468150263954,
        "y": 279.9192344903515
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "options",
            "options": [
              {
                "label": "gemini-pro",
                "name": "gemini-pro"
              }
            ],
            "default": "gemini-pro",
            "id": "chatGoogleGenerativeAI_0-input-modelName-options"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "{{inMemoryCache_0.data.instance}}",
          "modelName": "gemini-pro",
          "temperature": "0.1",
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 574,
      "selected": false,
      "positionAbsolute": {
        "x": 829.4468150263954,
        "y": 279.9192344903515
      },
      "dragging": false
    },
    {
      "id": "conversationalAgent_0",
      "position": {
        "x": 2257.1605391529183,
        "y": -218.6464149083413
      },
      "type": "customNode",
      "data": {
        "id": "conversationalAgent_0",
        "label": "Conversational Agent",
        "version": 3,
        "name": "conversationalAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "rows": 4,
            "default": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
            "optional": true,
            "additionalParams": true,
            "id": "conversationalAgent_0-input-systemMessage-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Allowed Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "conversationalAgent_0-input-tools-Tool"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "conversationalAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": "",
          "model": "",
          "memory": "",
          "systemMessage": "Assistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalAgent_0-output-conversationalAgent-AgentExecutor|BaseChain|Runnable",
            "name": "conversationalAgent",
            "label": "AgentExecutor",
            "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 434,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2257.1605391529183,
        "y": -218.6464149083413
      }
    },
    {
      "id": "inMemoryCache_0",
      "position": {
        "x": 352.2025807619706,
        "y": 739.3023187008392
      },
      "type": "customNode",
      "data": {
        "id": "inMemoryCache_0",
        "label": "InMemory Cache",
        "version": 1,
        "name": "inMemoryCache",
        "type": "InMemoryCache",
        "baseClasses": [
          "InMemoryCache",
          "BaseCache"
        ],
        "category": "Cache",
        "description": "Cache LLM response in memory, will be cleared once app restarted",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
            "name": "inMemoryCache",
            "label": "InMemoryCache",
            "description": "Cache LLM response in memory, will be cleared once app restarted",
            "type": "InMemoryCache | BaseCache"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "positionAbsolute": {
        "x": 352.2025807619706,
        "y": 739.3023187008392
      },
      "dragging": false
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": 1598.9238213403003,
        "y": -575.0251455425464
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 2,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "nebula_info",
          "description": "Use this tool when questions were asked about nebula9.\n    A document has been provided with information on nebula9 company details which can be used to answer the customer's questions and provide information on the services offered by nebula9 company. When using this information in responses, the assistant keeps answers short and relevant to the user's query. \n",
          "retriever": "{{memoryVectorStore_0.data.instance}}",
          "returnSourceDocuments": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 602,
      "selected": false,
      "positionAbsolute": {
        "x": 1598.9238213403003,
        "y": -575.0251455425464
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": 836.9833667550324,
        "y": -587.1620909699509
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{docxFile_0.data.instance}}"
          ],
          "embeddings": "{{googleGenerativeAiEmbeddings_0.data.instance}}",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 405,
      "selected": false,
      "positionAbsolute": {
        "x": 836.9833667550324,
        "y": -587.1620909699509
      },
      "dragging": false
    },
    {
      "id": "docxFile_0",
      "position": {
        "x": 458.2189828203627,
        "y": -582.5709618491513
      },
      "type": "customNode",
      "data": {
        "id": "docxFile_0",
        "label": "Docx File",
        "version": 1,
        "name": "docxFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from DOCX files",
        "inputParams": [
          {
            "label": "Docx File",
            "name": "docxFile",
            "type": "file",
            "fileType": ".docx",
            "id": "docxFile_0-input-docxFile-file"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "docxFile_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "docxFile_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "metadata": ""
        },
        "outputAnchors": [
          {
            "id": "docxFile_0-output-docxFile-Document",
            "name": "docxFile",
            "label": "Document",
            "description": "Load data from DOCX files",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 411,
      "selected": false,
      "positionAbsolute": {
        "x": 458.2189828203627,
        "y": -582.5709618491513
      },
      "dragging": false
    },
    {
      "id": "googleGenerativeAiEmbeddings_0",
      "position": {
        "x": 1219.1308078379973,
        "y": -646.0195050166735
      },
      "type": "customNode",
      "data": {
        "id": "googleGenerativeAiEmbeddings_0",
        "label": "GoogleGenerativeAI Embeddings",
        "version": 1,
        "name": "googleGenerativeAiEmbeddings",
        "type": "GoogleGenerativeAiEmbeddings",
        "baseClasses": [
          "GoogleGenerativeAiEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Google Generative API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "googleGenerativeAiEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "options",
            "options": [
              {
                "label": "embedding-001",
                "name": "embedding-001"
              }
            ],
            "default": "embedding-001",
            "id": "googleGenerativeAiEmbeddings_0-input-modelName-options"
          },
          {
            "label": "Task Type",
            "name": "tasktype",
            "type": "options",
            "description": "Type of task for which the embedding will be used",
            "options": [
              {
                "label": "TASK_TYPE_UNSPECIFIED",
                "name": "TASK_TYPE_UNSPECIFIED"
              },
              {
                "label": "RETRIEVAL_QUERY",
                "name": "RETRIEVAL_QUERY"
              },
              {
                "label": "RETRIEVAL_DOCUMENT",
                "name": "RETRIEVAL_DOCUMENT"
              },
              {
                "label": "SEMANTIC_SIMILARITY",
                "name": "SEMANTIC_SIMILARITY"
              },
              {
                "label": "CLASSIFICATION",
                "name": "CLASSIFICATION"
              },
              {
                "label": "CLUSTERING",
                "name": "CLUSTERING"
              }
            ],
            "default": "TASK_TYPE_UNSPECIFIED",
            "id": "googleGenerativeAiEmbeddings_0-input-tasktype-options"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "embedding-001",
          "tasktype": "TASK_TYPE_UNSPECIFIED"
        },
        "outputAnchors": [
          {
            "id": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
            "name": "googleGenerativeAiEmbeddings",
            "label": "GoogleGenerativeAiEmbeddings",
            "description": "Google Generative API to generate embeddings for a given text",
            "type": "GoogleGenerativeAiEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 468,
      "selected": false,
      "positionAbsolute": {
        "x": 1219.1308078379973,
        "y": -646.0195050166735
      },
      "dragging": false
    },
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": 94.12800696955838,
        "y": -591.7505451167897
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number"
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": "50",
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 429,
      "selected": false,
      "positionAbsolute": {
        "x": 94.12800696955838,
        "y": -591.7505451167897
      },
      "dragging": false
    },
    {
      "id": "mrklAgentChat_0",
      "position": {
        "x": 1684.1610784441455,
        "y": 320.18678371982855
      },
      "type": "customNode",
      "data": {
        "id": "mrklAgentChat_0",
        "label": "ReAct Agent for Chat Models",
        "version": 4,
        "name": "mrklAgentChat",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses the ReAct logic to decide what action to take, optimized to be used with Chat Models",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Allowed Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "mrklAgentChat_0-input-tools-Tool"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "mrklAgentChat_0-input-model-BaseChatModel"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "mrklAgentChat_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "mrklAgentChat_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{retrieverTool_0.data.instance}}",
            "{{customTool_0.data.instance}}"
          ],
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "memory": "{{bufferMemory_1.data.instance}}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "mrklAgentChat_0-output-mrklAgentChat-AgentExecutor|BaseChain|Runnable",
            "name": "mrklAgentChat",
            "label": "AgentExecutor",
            "description": "Agent that uses the ReAct logic to decide what action to take, optimized to be used with Chat Models",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 382,
      "positionAbsolute": {
        "x": 1684.1610784441455,
        "y": 320.18678371982855
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "bufferMemory_1",
      "position": {
        "x": 623.3602008770001,
        "y": -115.35220511475929
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_1",
        "label": "Buffer Memory",
        "version": 1,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Remembers previous conversational back and forths directly",
        "inputParams": [
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "id": "bufferMemory_1-input-memoryKey-string"
          },
          {
            "label": "Input Key",
            "name": "inputKey",
            "type": "string",
            "default": "input",
            "id": "bufferMemory_1-input-inputKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "memoryKey": "chat_history",
          "inputKey": "input"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Remembers previous conversational back and forths directly",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 376,
      "positionAbsolute": {
        "x": 623.3602008770001,
        "y": -115.35220511475929
      },
      "selected": false,
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "inMemoryCache_0",
      "sourceHandle": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
      "target": "chatGoogleGenerativeAI_0",
      "targetHandle": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
      "type": "buttonedge",
      "id": "inMemoryCache_0-inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache-chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-input-cache-BaseCache"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "docxFile_0",
      "targetHandle": "docxFile_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-docxFile_0-docxFile_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "docxFile_0",
      "sourceHandle": "docxFile_0-output-docxFile-Document",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "docxFile_0-docxFile_0-output-docxFile-Document-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "googleGenerativeAiEmbeddings_0",
      "sourceHandle": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "googleGenerativeAiEmbeddings_0-googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    },
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "mrklAgentChat_0",
      "targetHandle": "mrklAgentChat_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-mrklAgentChat_0-mrklAgentChat_0-input-tools-Tool"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "mrklAgentChat_0",
      "targetHandle": "mrklAgentChat_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-mrklAgentChat_0-mrklAgentChat_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_1",
      "sourceHandle": "bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "mrklAgentChat_0",
      "targetHandle": "mrklAgentChat_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "bufferMemory_1-bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-mrklAgentChat_0-mrklAgentChat_0-input-memory-BaseChatMemory"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
      "target": "mrklAgentChat_0",
      "targetHandle": "mrklAgentChat_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-mrklAgentChat_0-mrklAgentChat_0-input-tools-Tool"
    }
  ]
}